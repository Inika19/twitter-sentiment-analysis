{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:36:09.246473Z",
     "start_time": "2020-02-13T18:36:06.136861Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:40:13.232593Z",
     "start_time": "2020-02-13T18:40:13.228188Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# print(train['negativereason_gold'].nunique())\n",
    "# print(train['negativereason_gold'].value_counts(),\"\\n\")\n",
    "\n",
    "# print(x_test.negativereason_gold.nunique())\n",
    "# print(x_test.negativereason_gold.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:43:11.349359Z",
     "start_time": "2020-02-13T18:43:11.342379Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "def deEmojify(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:54:09.901111Z",
     "start_time": "2020-02-13T18:54:09.807250Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"twitter_train.csv\") #10980 rows 12 cols\n",
    "test = pd.read_csv(\"twitter_test.csv\")\n",
    "\n",
    "drop_cols = ['airline_sentiment_gold','name','tweet_id', 'retweet_count','tweet_created','user_timezone','tweet_coord','tweet_location']\n",
    "train.drop(drop_cols, axis = 1, inplace=True)\n",
    "test.drop(drop_cols, axis = 1, inplace=True)\n",
    "\n",
    "stops = stopwords.words('english')\n",
    "stops += list(punctuation)\n",
    "stops += ['flight','airline','flights','AA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:54:16.924187Z",
     "start_time": "2020-02-13T18:54:10.467469Z"
    }
   },
   "outputs": [],
   "source": [
    "abbreviations = {'ppl': 'people','cust':'customer','serv':'service','mins':'minutes','hrs':'hours','svc': 'service',\n",
    "           'u':'you','pls':'please'}\n",
    "\n",
    "train_index = train[~train.negativereason_gold.isna()].index\n",
    "test_index = test[~test.negativereason_gold.isna()].index\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    tweet = row.text\n",
    "    \n",
    "    row.text = deEmojify(row.text)\n",
    "    \n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',tweet) #remove links\n",
    "    tweet = re.sub('@[^\\s]+','',tweet) #remove usernames\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet) #remove additional whitespaces\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) #replace #word with word\n",
    "    tweet = tweet.strip('\\'\"') #trim tweet\n",
    "    \n",
    "    words = []\n",
    "    for word in tweet.split():\n",
    "        if not hasNumbers(word):\n",
    "            if word.lower() not in stops:\n",
    "                if word in list(abbreviations.keys()):\n",
    "                    words.append(abbreviations[word])\n",
    "                else:\n",
    "                    words.append(word.lower())   \n",
    "    \n",
    "    tweet = \" \".join(words)\n",
    "    tweet = \" %s %s\" % (tweet, row.airline)\n",
    "    row.text = tweet\n",
    "    if index in train_index:\n",
    "        row.text = \" %s %s\" % (row.text, row.negativereason_gold)\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    tweet = row.text\n",
    "    row.text = deEmojify(row.text)\n",
    "    \n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',tweet) #remove links\n",
    "    tweet = re.sub('@[^\\s]+','',tweet) #remove usernames\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet) #remove additional whitespaces\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) #replace #word with word\n",
    "    tweet = tweet.strip('\\'\"') #trim tweet\n",
    "    \n",
    "    words = []\n",
    "    for word in tweet.split(): \n",
    "        if not hasNumbers(word):\n",
    "            if word.lower() not in stops:\n",
    "                if word in list(abbreviations.keys()):\n",
    "                    words.append(abbreviations[word])\n",
    "                else:\n",
    "                    words.append(word.lower())\n",
    "    \n",
    "    tweet = \" \".join(words)\n",
    "    tweet = \" %s %s\" % (tweet, row.airline)\n",
    "    row.text = tweet\n",
    "    if index in test_index:\n",
    "        row.text = \" %s %s\" % (row.text, row.negativereason_gold)\n",
    "\n",
    "del train['negativereason_gold']\n",
    "del test['negativereason_gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:43:25.101114Z",
     "start_time": "2020-02-13T18:43:25.088669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>scheduled morning, days fact, yes..not sure e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>seeing workers time time going beyond love fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>flew ord miami back great crew, service legs....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>that's horse radish Southwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>ord delayed air force one, last sbn minutes l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment    airline  \\\n",
       "0          negative  Southwest   \n",
       "1          positive  Southwest   \n",
       "2          positive     United   \n",
       "3          negative  Southwest   \n",
       "4          negative     United   \n",
       "\n",
       "                                                text  \n",
       "0   scheduled morning, days fact, yes..not sure e...  \n",
       "1   seeing workers time time going beyond love fl...  \n",
       "2   flew ord miami back great crew, service legs....  \n",
       "3                      that's horse radish Southwest  \n",
       "4   ord delayed air force one, last sbn minutes l...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating vocab formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:54:17.192540Z",
     "start_time": "2020-02-13T18:54:16.927646Z"
    }
   },
   "outputs": [],
   "source": [
    "v = TfidfVectorizer(analyzer='word', max_features=3150, max_df = 0.8, ngram_range=(1,1))\n",
    "train_features= v.fit_transform(train.text)\n",
    "test_features=v.transform(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:54:17.342465Z",
     "start_time": "2020-02-13T18:54:17.196601Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C = 2.1, solver='liblinear', multi_class='auto') #Best Performance. SCORED: 0.7929\n",
    "clf.fit(train_features,train['airline_sentiment'])\n",
    "pred = clf.predict(test_features)\n",
    "with open('logreg.csv', 'w') as f:\n",
    "    for item in pred:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:51:14.977462Z",
     "start_time": "2020-02-13T18:51:03.338395Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = SVC(kernel=\"linear\", C= 0.96 , gamma = 'scale') # SCORED .78\n",
    "# clf = SVC(C = 1000, gamma = 0.001)\n",
    "clf.fit(train_features, train['airline_sentiment'])\n",
    "pred = clf.predict(test_features)\n",
    "\n",
    "with open('svc.csv', 'w') as f: #less accurate\n",
    "    for item in pred:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:49:41.268169Z",
     "start_time": "2020-02-13T18:49:41.257571Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# v.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:51:15.035582Z",
     "start_time": "2020-02-13T18:51:14.981431Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB #score: 0.7374\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_features,train['airline_sentiment'])\n",
    "y_pred = clf.predict(test_features)\n",
    "with open('nb.csv', 'w') as f: \n",
    "    for item in y_pred:\n",
    "        f.write(\"%s\\n\" % item) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
